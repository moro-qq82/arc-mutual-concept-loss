

created by gemini 2.5 pro

主な変更点は以下の通り:
1.  **データセットの変更**：既知のプリミティブ合成タスクから、ARC-AGI-2（K-shotタスク解決）に変更。
2.  **モデルアーキテクチャの変更**：単純なEncoder-Decoderから、K-shotの例題（コンテキスト）を処理できるMeta-Learning/In-Context Learning型アーキテクチャ（例：Transformerベース）に変更。
3.  **損失関数の変更**：
    * `L_prim`（プリミティブ分類損失）は、ARCにはラベルがないため**削除**。
    * `L_share`（サブスペース共有正則化）の**グルーピング方法を変更**。プリミティブラベルの代わりに、**疎AE（SAE）によって発見された「潜在的プリミティブ（疎特徴z）」の活性化パターン**に基づいてタスクをグループ化する。
4.  **評価の変更**：「未見の合成（長3）」から「未見のARCタスク」の正解率に変更。

---

# 実験計画書：共有サブスペースXに基づくARC-AGI-2タスク一般化の検証（修正案）

## 0. 要旨（アブストラクト）
本計画は、表現空間にタスク横断で再利用可能な**共有サブスペースX**を形成させる軽量手法（サブスペース共有正則化＋疎オートエンコーダ補助）により、
(1) **ARC-AGI-2の未見タスク**への一般化（In-Context Learning性能）、(2) （メタ学習的な）few-shot適応、(3) 学習時間短縮が同時に改善されることを、単一GPU・ミニ実装で検証する。

---

## 1. 背景と問題意識
- 現行のAIは大規模事前学習により高性能だが、**抽象的推論**や**極端な少データ一般化**（例：ARCタスク）に課題が残る。
- 人間の推論は、少数例から**潜在的な「ルール」や「操作プリミティブ」**を抽出し、それを再利用している。
- 我々の作業仮説：モデル表現（特にタスクの「解法ルール」を捉えるベクトル）に**共有サブスペースX**を明示的に持たせ、その再利用を促すと、少ない例から新規タスクに効率よく適応できる。

---

## 2. 目的（検証したい主張）
1.  **共有サブスペースX形成**（潜在的ルールの部品化）を促す軽量な学習目標で、未見のARCタスクに対する**In-Context Learning性能（K-shot正解率）**が改善する。
2.  上記効果は、**学習時間（到達ステップ/壁時計時間）**の観点でも有意。
3.  表現解析（CKA/Grassmann距離・疎特徴の可視化）により、**Xの存在と再利用**（例：類似の操作を行うタスク群が共通のサブスペースや疎特徴を共有）を定量・定性に確認できる。

---

## 3. 実験デザインの概要
- **データ**：**ARC-AGI-2データセット**。
  - 各サンプルは1つの「タスク」であり、K個（例：3〜5個）の「学習例ペア（入力グリッド、出力グリッド）」と1個の「テスト入力グリッド」から成る。
  - 目標は「テスト出力グリッド」を正確に予測すること。
  - 公式提供の `train.jsonl`（学習）、`validation.jsonl`（検証）、`test.jsonl`（評価）のスプリットを採用し、追加の独自分割は後述のルールに従って作成する。
- **モデル**：**K-shot In-Context Learningモデル**（例：小型Transformer）。
  - **Grid Encoder** (例: CNN) が各グリッドをベクトル化。
  - **Context Encoder** (例: Transformer) がK個の学習例ペア `(in_1, out_1), ..., (in_K, out_K)` を処理し、**タスク表現 $h_{task}$** を抽出する。
  - **Solver** (例: Transformer Decoder) が `(test_in, h_{task})` を条件として `test_out` を予測（回帰またはトークンごとの分類）。
  - **疎AE**：**$h_{task}$** → $z$（疎）→ $\hat{h}_{task}$ の再構成で“解法ルールの部品化”。
- **鍵となる損失**：
  - **サブスペース共有正則化**：
    - SAEの中間特徴 $z$ の**活性化パターン**に基づき、バッチ内のタスクを**動的にグループ化**（例：特徴 $z_j$ が活性化したタスク群 $G_j$）。
    - $G_j$ に属する $h_{task}$ の表現行列の上位k主成分から射影行列 $P_j$ を作り、グループ群の平均射影 $\bar P$ との二乗距離を最小化。
  - **疎AE補助**（L1による疎性＋再構成MSE）。
  - **タスク損失**（テスト出力グリッドのCE / ピクセル単位Acc）。
- **（削除）**：プリミティブ多ラベルBCE（ARCにはラベルがないため）。

---

## 4. 仮説と評価指標
- **H1（タスク一般化）**：提案法はB0（ベースライン）より、未見ARCタスク（テストセット）での**タスク正解率（Top-1 / Top-3）**または**ピクセルAcc/IoU**が有意に高い。
- **H2（少データ適応）**：[変更] 未見タスク群（例：100タスク）への**メタ適応**（追加ファインチューニング）において、**タスク数–性能**曲線・**到達ステップ**が優位。
- **H3（学習時間効率）**：val-Acc到達までの**学習ステップ/時間**を短縮。
- **H4（表現の共有）**：**SAE特徴 $z_j$ によって定義されたタスク群**間の**CKA/Grassmann距離**が小さく、共有度が高い。疎特徴 $z$ がARCの（人間が解釈可能な）**潜在的操作**（例：「色の置換」「図形のコピー」）と有意に対応。

**主要指標と優先順位**：
1. **主指標**：タスク単位Top-1正解率（K-shot In-Context Learning）。全テストタスク集合 $\mathcal{T}$ に対し、各タスクの予測出力が完全一致した割合を計算し、タスク平均を報告する。
2. **副指標A**：タスク単位Top-3正解率。タスクごとに上位3候補のうち正解が含まれるかで判定し、タスク平均を報告する。Top-k評価では $k=1,3$ を使用する。
3. **副指標B**：テストグリッド単位ピクセルAccuracy。予測グリッドと正解グリッドを各ピクセルごとに二値比較し（閾値はRGB値一致／離散色ID一致）、タスク内グリッド平均→タスク平均の順に集計する。
4. **副指標C**：テストグリッド単位IoU。ピクセルを正解マスク vs 予測マスクに二値化し、**同一色一致を指標**とする。判定は色一致の二値化で閾値0.5（一致=1、不一致=0）を適用し、グリッド平均→タスク平均で報告する。
5. **副指標D**：メタ適応における到達ステップ数・壁時計時間（タスク適応ループでの中央値）。
6. **副指標E**：共有度解析指標（SAE特徴グループ間CKA/Grassmann距離の平均・標準偏差、線形プローブ転移精度）。

**集計単位と計算式（概要）**：
- **タスク単位Top-1正解率**：$\text{Acc}_{task} = \frac{1}{|\mathcal{T}|}\sum_{t \in \mathcal{T}} \mathbf{1}[\hat{Y}^{(1)}_t = Y_t]$。$\hat{Y}^{(1)}_t$ はタスク $t$ のTop-1予測。
- **タスク単位Top-3正解率**：$\text{Acc}^{(3)}_{task} = \frac{1}{|\mathcal{T}|}\sum_{t \in \mathcal{T}} \mathbf{1}[Y_t \in \{\hat{Y}^{(1)}_t, \hat{Y}^{(2)}_t, \hat{Y}^{(3)}_t\}]$。
- **ピクセルAccuracy**：タスク $t$ の各テストグリッド集合 $\mathcal{G}_t$ について $\text{PixAcc}_t = \frac{1}{|\mathcal{G}_t|}\sum_{g \in \mathcal{G}_t} \frac{1}{|\Omega_g|}\sum_{p \in \Omega_g} \mathbf{1}[\hat{c}_{gp} = c_{gp}]$。最終報告は $\frac{1}{|\mathcal{T}|}\sum_t \text{PixAcc}_t$。
- **IoU**：グリッド $g$ 内の各色に対し二値化した集合でIoUを計算し、色平均→グリッド平均をとる。二値化はピクセル色一致で閾値0.5。タスク集計は $\text{IoU}_t = \frac{1}{|\mathcal{G}_t|}\sum_{g \in \mathcal{G}_t} \text{IoU}(g)$、最終報告はタスク平均。
- **メタ適応到達指標**：各タスクで目標精度（例：Top-1 90%）到達に必要な学習ステップ/時間を計測し、タスク中央値を提示。時間は壁時計時間を秒単位で記録。

---

## 5. ベースラインとアブレーション

### 5.1 共通ハイパーパラメータとトレーニングスケジュール
- **最適化手法**：AdamW（\(\beta_1=0.9, \beta_2=0.95\)、weight decay 0.02）。
- **初期学習率**：$2\times10^{-4}$ を基準値とし、**ウォームアップ 2\,000 step → 余弦減衰**で総ステップの90%まで線形減衰後、残り10%はフラット。
- **推奨バッチサイズ**：学習タスク 64（GPUメモリ16GB想定）。12GB級では 48、24GB級では 96 まで拡張可。
- **学習率スイープ範囲**：$[1\times10^{-4},\;4\times10^{-4}]$ を主探索レンジとし、必要に応じて $6\times10^{-4}$ まで拡張。
- **勾配クリップ**：グローバルノルム 1.0。
- **混合精度**：BF16推奨（AMP自動スケール）。
- **訓練スケジュール**：総ステップ 120k、各ベースラインで同一の**チェックポイント保存間隔 2k step**、**評価間隔 4k step**。早期停止は検証正解率が 8 評価連続で改善しない場合。

### 5.2 ベースライン固有設定・例外
- **B0**：標準学習（共有正則化・疎AEなし）。共通設定をそのまま使用。
- **B1**：補助のみ（疎AE、共有正則化なし）。共通設定＋疎AE再構成重み \(\beta=0.1\) を固定。
- **B2**：共有のみ（共有正則化、疎AEなし）。
  - **例外**：SAEを使わないため、グルーピングは **$h_{task}$ のk-meansクラスタリング**（クラスタ数 = バッチサイズの1/4を基準）を使用し、安定化のために**ウォームアップ終了後に\(\alpha\)を0.05→0.1へ線形増加**。
- **B3**：疎AEの**非疎**（L1=0）。再構成MSEは共通設定と同一。
- **B4**：few-shot（メタ適応）で**Adapter/LoRAなし**の全層微調整。
  - **例外**：全層更新に伴い**推奨バッチサイズ 48**まで縮小し、学習率スイープ上限を $2\times10^{-4}$ に制限。
- **B5**：**Context Encoder**のアーキテクチャ比較（例：Transformer vs Deep Sets vs GRU）。
  - **例外**：GRU版のみ勾配爆発対策として**勾配クリップ 0.5**に変更。
- **B6**：サブスペース次元kのスイープ（8/16/32）。共通設定に従い、\(\alpha\)は $0.05, 0.1, 0.2$ の組み合わせで評価。

---

## 6. 手順（プロトコル）
1.  **データ準備**：ARC-AGI-2データローダー準備（学習/検証/テスト）。詳細な分割と整形手順は後述の「データ準備手順」を参照。
2.  **事前学習**：ARC学習セットで学習。損失 $\mathcal{L}=\mathcal{L}_{task}+\alpha\mathcal{L}_{share}+\beta\mathcal{L}_{sae}$。初期設定：$\alpha=0.1, \beta=0.1$。
3.  **In-Context Learning評価**：未見タスク（テストセット）で性能測定（**勾配更新なし**）。
4.  **few-shotメタ適応**：[変更] 未見タスク群（例：50〜100タスク）で**LoRA/AdapterをContext Encoder近傍に限定**し微調整（≤500 step）。
5.  **学習時間記録**：同一GPUで学習曲線（step vs val-Acc）と壁時計時間をログ。
6.  **表現解析**：
    - SAE特徴 $z_j$ でグループ化したタスク群間のCKA/Grassmann距離。
    - SAEの $z$ とタスクの（人間による）カテゴリ分類との相関・活性ヒートマップ。

### データ準備手順
1. **公式スプリットの取得**：ARC-AGI-2配布物に含まれる `train.jsonl`、`validation.jsonl`、`test.jsonl` を `data/raw/` に配置し、ファイル構造を変更しない。
2. **検証タスクIDの固定化**：`validation.jsonl` 内のタスクIDを昇順に並べたリストを生成し、`data/splits/val_tasks.json` として保存する。学習・評価スクリプトではこのリストを読み込み、検証順序とバッチングを固定する。
3. **メタ適応用テストサブセット**：未見タスクの評価対象として `test.jsonl` から指定数（例：100件）のタスクを抽出する。抽出時はPythonの `random`、`numpy.random`、`torch` にシード `20250214` を設定し、重複なしでサンプリングした結果を `data/splits/meta_eval_test.json` に保存する。
4. **K-shot例の整形**：各タスクに含まれる学習例ペアを、入出力グリッドの配列とメタデータをまとめた辞書形式に変換し、`data/processed/{task_id}.json` として書き出す。例数がKを超える場合は後述のルールに従いサブサンプリングした上で保存する。
5. **処理ログの記録**：前処理スクリプトの実行コマンド、Gitリビジョン、処理日時を `logs/data_preparation.log` に追記し、使用した設定ファイルを `configs/data_prep.yaml` に保持する。

### K-shot例の選定ルール
- **最大例数への揃え**：各タスクの利用可能な学習例数がK未満の場合は全例を使用し、Kを超える場合はK個を選定する。
- **乱数シードの固定**：サブサンプリングは乱数シード `20250214` を設定した状態で一度だけ実行し、選択されたインデックスを `data/splits/kshot_indices/{task_id}.json` に保存して再利用する。
- **順序の一貫性**：保存時およびローダー読み込み時にはインデックスを昇順に並べ替え、その順番でモデルへ入力する。追加のシャッフルは行わない。
- **タスク横断の統一**：ミニバッチ作成時に必要なK個の例が揃わないタスクはバッチから除外し、補完のための重複例挿入は行わない。

### 再現性確保のためのシードと保存場所
- **共通シード**：データ前処理・K-shotサンプリング・学習初期化に共通して乱数シード `20250214` を用いる。追加のシード設定が必要な場合は `configs/seed.yaml` に明記する。
- **分割ファイルの管理**：`data/splits/` 配下に `val_tasks.json`、`meta_eval_test.json`、`kshot_indices/` を配置し、バージョン管理対象とする。
- **ログと設定ファイル**：`logs/` 以下に `data_preparation.log` を作成して更新履歴を残し、対応する設定値は `configs/data_prep.yaml` に保存する。

---

## 7. 実装上の簡素化と安定化策
- **PCA**：`torch.pca_lowrank`で小規模バッチから上位k次元。平均射影は**detach**、1–Nステップごと更新。
- **グループ分け**：[変更] バッチ内で**SAE特徴 $z_j$ が閾値以上で活性化したタスク**をグループ $G_j$ とする。バッチ内に最低（例：16）サンプル以上存在する $j$ のみで $\mathcal{L}_{share}$ を計算。
- **疎化**：L1はウォームアップで増加。過疎/過密を監視し $\lambda$ を自動調整（目標平均活性率）。
- **過度共有の回避**：$\alpha$ を0.05–0.2でスイープ。早期停止を併用。

---

## 8. 計算資源とタイムライン
- **資源**：単一GPU（**3090/A100/H100推奨**。ARCはT4/V100では厳しい可能性）。
- **所要**：[変更] 学習**12–48時間**、適応各数分〜十数分（環境依存）。
- **タイムライン**：
  - Week 1：データローダー・ベースラインモデル（B0）実装、初期学習。
  - Week 2：共有正則化・疎AE追加、In-Context評価。
  - Week 3：メタ適応、表現解析。
  - Week 4：アブレーション、図表作成・短報ドラフト。

---

## 9. 期待される結果と意義
- 共有サブスペース正則化＋疎AEにより、**未見ARCタスクの正解率**が上昇し、**到達時間**が短縮。
- 解析により、**SAE特徴グループ間のサブスペースの収束**と**疎特徴の（解釈可能な）潜在的ルール対応**を確認。
- ARCタスクにおける**抽象的ルールの部品化と再利用**の実現に向けた、シンプルなベースラインを提供。

---

## 10. リスクと代替案
- **PCA不安定**：グループサイズ拡大、EMA平均。
- **表現崩壊**：$\alpha$ を縮小、補助損失の重み調整。
- **[変更] タスクが困難すぎる**：ベースライン（B0）の正解率が0%に近い場合、改善が観測困難。→ **ARCの簡易版**（例：色のみ、形状のみのタスク）や、より解きやすい**1D-ARC**等でまず手法の有効性を検証する。
- **[新規] SAEが自明な特徴を獲得**：$\lambda$ の調整、SAEのアーキテクチャ見直し。

---

## 11. 公開物と再現性
- コード（ARCローダー＋モデル＋損失関数）。
- ログとシード、ハイパラ表、チェックポイント。
- 図：学習曲線、タスク正解率バー、CKA/Grassmannヒートマップ、**SAE特徴 $z_j$ が捉えたタスク群の可視化例**。

---

## 12. 短報ドラフト構成（目安）
(変更なし)

---

## 付録A：損失の定式化（簡易）
- タスク損失：$\mathcal{L}_{task}=\text{CE}(\hat{Y}_{test}, Y_{test})$。
- 疎AE：$h = h_{task}$。$\mathcal{L}_{sae}=\|h-\hat h\|_2^2+\lambda\|z\|_1$。
- 共有正則化：[変更] グループ $G_j$ = $\{h_i \mid z_i[j] > \theta\}$（バッチ $i$ 内で $j$ が活性化したタスク）。
  - $H_j$ (中心化表現行列) から $U_j=\mathrm{PCA}_k(H_j)$、\(P_j=U_jU_j^T\)。
  - $\bar P=\frac{1}{|J|}\sum_{j \in J} P_j$ ($J$ は有効な特徴インデックス集合)。
  \[\mathcal{L}_{share}=\frac{1}{|J|}\sum_{j \in J} \|P_j-\bar P\|_F^2\]
- **（削除）**：$\mathcal{L}_{prim}$。
- 総損失：$\mathcal{L}=\mathcal{L}_{task}+\alpha\mathcal{L}_{share}+\beta\mathcal{L}_{sae}$。

---

## 付録B：few-shotメタ適応の範囲
- LoRA/Adapterは**Context Encoder**または**Solver**のTransformer層に限定。学習率小、step ≤ 500。
- 早期停止基準：メタ適応用の検証タスク群での正解率改善停滞。